
<!DOCTYPE html>
<html lang='en'>
<head>
<title>Streaming Data Processing: Streaming Data Pipelines | Qwiklabs</title>
<meta name="action-cable-url" content="/cable" />
<script>
//<![CDATA[
window.gon={};gon.deployment="googlecoursera-run";
//]]>
</script>
<script>
  (function(w,d,s,l,i){w[l]=w[l]||[];w[l].push({'gtm.start':
  new Date().getTime(),event:'gtm.js'});var f=d.getElementsByTagName(s)[0],
  j=d.createElement(s),dl=l!='dataLayer'?'&l='+l:'';j.async=true;j.src=
  'https://www.googletagmanager.com/gtm.js?id='+i+dl;f.parentNode.insertBefore(j,f);
  })(window,document,'script','dataLayer',"GTM-5XSKHDX");
</script>
<script src="https://cdn.qwiklabs.com/assets/hallofmirrors/polyfills/webcomponents-loader-b1b28b59480cca2ab0c23485f64ba2ec8893bdc9.js"></script>
<script src="https://cdn.qwiklabs.com/assets/vendor-730738e6a42cf2d08765342db72a96e1c168e026.js"></script>
<script src="https://cdn.qwiklabs.com/assets/application-5bdf08e3db82244d1fd919ef04497683c2eb8f48.js"></script>
<script src="https://cdn.qwiklabs.com/assets/hallofmirrors/hallofmirrors-5be9380d7cac08f7e2dac9c53445a154bd807c47.js"></script>
<script id='ze-snippet' src='https://static.zdassets.com/ekr/snippet.js?key=511e4158-0aec-4e3c-b2e6-4daa1769f51e'></script>


<meta name="csrf-param" content="authenticity_token" />
<meta name="csrf-token" content="dCKkc4EUr/dILix0khE6t0UvHRXQVQbmf2s+h45mSKHMYijpTNI5yPtgoD/7VPFmv6ajg5bf5w4r2BFMWQYGCA==" />
<meta content='width=device-width, initial-scale=1.0, user-scalable=yes' name='viewport'>
<meta content='1rRsY0INj8RvwB5EF5pwdxt2A2P9aDgAlsICaJ0d5w0' name='google-site-verification'>
<meta content='#3681E4' property='msapplication-TileColor'>
<meta content='/favicon-144.png' property='msapplication-TileImage'>
<meta content='[{&quot;id&quot;:&quot;recaptcha_experiment&quot;,&quot;optimize_id&quot;:&quot;dpViOcLkT3qS4TvL2mRojA&quot;,&quot;title&quot;:&quot;No Recaptcha shown for trusted users&quot;,&quot;variant_index&quot;:0,&quot;variant&quot;:&quot;original&quot;}]' name='active-experiments'>
<meta content='{&quot;userId&quot;:12197799,&quot;experimentIds&quot;:[&quot;organization_announcements&quot;,&quot;organization_learning_plans&quot;,&quot;chat_off_for_signed_out_users&quot;,&quot;alexandria_show_bundle_errors&quot;,&quot;program_announcements&quot;,&quot;canonical_domain_redirect&quot;,&quot;program_learning_assignment&quot;,&quot;barker&quot;,&quot;used_in&quot;,&quot;course_upgrade&quot;,&quot;community_forum&quot;,&quot;peer_assignment&quot;,&quot;enforce_codebuild_verdicts&quot;,&quot;show_annual_purchase_now&quot;,&quot;oauth_risc_shutoff&quot;,&quot;teams&quot;,&quot;content_provider_admin&quot;]}' name='help-api-product-data'>
<meta content='{&quot;groupIds&quot;:[&quot;non_suadmins&quot;,&quot;students&quot;,&quot;non_organization&quot;,&quot;non_program&quot;]}' name='help-api-custom-data'>
<meta content='Streaming Data Processing: Streaming Data Pipelines' name='description'>
<meta content='Qwiklabs' name='author'>
<meta content='Streaming Data Processing: Streaming Data Pipelines | Qwiklabs' property='og:title'>
<meta content='website' property='og:type'>
<meta content='/favicon-144.png' property='og:image'>
<meta content='Qwiklabs' property='og:site_name'>
<meta content='Streaming Data Processing: Streaming Data Pipelines' property='og:description'>
<meta content='/qwiklabs_logo_900x887.png' property='og:logo' size='900x887'>
<meta content='/qwiklabs_logo_994x187.png' property='og:logo' size='994x187'>


<meta property="og:url" content="https://googlecoursera.qwiklabs.com/focuses/32528955?parent=lti_session" /><link href="https://googlecoursera.qwiklabs.com/focuses/32528955?parent=lti_session" rel="canonical" />
<link color='#3681E4' href='/favicon-svg.svg' rel='mask-icon'>
<link href='/favicon-180.png' rel='apple-touch-icon-precomposed'>
<link href='/favicon-32.png' rel='shortcut icon' type='image/x-icon'>


<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Oswald:400|Roboto+Mono:400,700|Roboto:300,400,500,700|Google+Sans:300,400,500,700|Google+Sans+Display:400|Material+Icons|Google+Material+Icons|Google+Sans+Text:400,500,700" media="screen" />

<link rel="stylesheet" href="https://cdn.qwiklabs.com/assets/application-29602dc272dc25b87d80aad082aeac190a74d2ab.css" media="all" />
<link rel="stylesheet" href="https://www.gstatic.com/glue/cookienotificationbar/cookienotificationbar.min.css" media="screen" />


<style>
  :root {
    --primary-text-on-surface-color: #1a73e8;
    --primary-text-on-surface-color-dark: #1568d6;
    --primary-text-on-surface-color-darker: #135ec1;
    --primary-text-on-surface-color-darkest: #1154ac;
    --primary-surface-color: #1a73e8;
    --primary-surface-color-rgb: 26,115,232;
    --primary-surface-color-light: #d1e3fa;
    --primary-surface-color-lightest: #e8f1fd;
    --text-on-primary-color: #ffffff;
    --accent-text-on-surface-color: #f29900;
    --accent-surface-color: #f9ab00;
    --accent-surface-color-rgb: 249,171,0;
    --accent-surface-color-light: #ffefcc;
    --text-on-accent-color: #202124;
  }
</style>



</head>
<body class='lab-show l-full no-nav application-new focuses focuses-show lab-show l-full no-nav '>
<div class='header-container'>
<div class='header'>
<ql-toolbar jumpEnabled>
<div class='header__title' slot='title'>
<ql-icon-button label="Back" href="https://www.coursera.org/" id="a135ad9a3bc05afa" target="_self" tip="Back">arrow_back</ql-icon-button>
<h1 class='ql-title-medium'>Streaming Data Processing: Streaming Data Pipelines</h1>
</div>
<div class='header__actions' slot='action'>
<ql-icon-button id='control-panel-target' style='display: none;'>
dashboard
</ql-icon-button>
<ql-menu for='control-panel-target' id='control-panel-menu'></ql-menu>
<ql-icon-button class='mobile-hide' icon='help_outline' id='help-menu-button' label='Open help menu' tip='Help'></ql-icon-button>
<ql-menu for='help-menu-button' id='help-menu'>
<ql-menu-item data-analytics-action='opened_help' data-analytics-label='lab' label='Help Center' onclick='hallofmirrors.helpService.startHelp({&quot;productData&quot;:{&quot;userId&quot;:12197799},&quot;context&quot;:&quot;lab&quot;})'></ql-menu-item>
<ql-menu-item href='mailto:support@qwiklabs.com' label='Email support'></ql-menu-item>
<ql-menu-item label='Chat support' onClick='ql.chat.open()'></ql-menu-item>
</ql-menu>

<ql-icon-button class='mobile-hide' icon='language' id='language' label='Select your language preference' tip='Language'></ql-icon-button>
<ql-menu for='language'>
<ql-menu-item data-analytics-action='changed_locale' data-analytics-label='ar' href='/focuses/32528955?locale=ar&amp;parent=lti_session' label='العربية‬‎' lang='ar'></ql-menu-item>
<ql-menu-item data-analytics-action='changed_locale' data-analytics-label='de' href='/focuses/32528955?locale=de&amp;parent=lti_session' label='Deutsch' lang='de'></ql-menu-item>
<ql-menu-item data-analytics-action='changed_locale' data-analytics-label='en' href='/focuses/32528955?locale=en&amp;parent=lti_session' label='English' lang='en'></ql-menu-item>
<ql-menu-item data-analytics-action='changed_locale' data-analytics-label='es' href='/focuses/32528955?locale=es&amp;parent=lti_session' label='español (Latinoamérica)' lang='es'></ql-menu-item>
<ql-menu-item data-analytics-action='changed_locale' data-analytics-label='fr' href='/focuses/32528955?locale=fr&amp;parent=lti_session' label='français' lang='fr'></ql-menu-item>
<ql-menu-item data-analytics-action='changed_locale' data-analytics-label='fr_CA' href='/focuses/32528955?locale=fr_CA&amp;parent=lti_session' label='français (Canada)' lang='fr-CA'></ql-menu-item>
<ql-menu-item data-analytics-action='changed_locale' data-analytics-label='he' href='/focuses/32528955?locale=he&amp;parent=lti_session' label='עברית' lang='he'></ql-menu-item>
<ql-menu-item data-analytics-action='changed_locale' data-analytics-label='id' href='/focuses/32528955?locale=id&amp;parent=lti_session' label='bahasa Indonesia' lang='id'></ql-menu-item>
<ql-menu-item data-analytics-action='changed_locale' data-analytics-label='it' href='/focuses/32528955?locale=it&amp;parent=lti_session' label='Italiano' lang='it'></ql-menu-item>
<ql-menu-item data-analytics-action='changed_locale' data-analytics-label='ja' href='/focuses/32528955?locale=ja&amp;parent=lti_session' label='日本語' lang='ja'></ql-menu-item>
<ql-menu-item data-analytics-action='changed_locale' data-analytics-label='ko' href='/focuses/32528955?locale=ko&amp;parent=lti_session' label='한국어' lang='ko'></ql-menu-item>
<ql-menu-item data-analytics-action='changed_locale' data-analytics-label='pl' href='/focuses/32528955?locale=pl&amp;parent=lti_session' label='Polski' lang='pl'></ql-menu-item>
<ql-menu-item data-analytics-action='changed_locale' data-analytics-label='pt_BR' href='/focuses/32528955?locale=pt_BR&amp;parent=lti_session' label='português (Brasil)' lang='pt-BR'></ql-menu-item>
<ql-menu-item data-analytics-action='changed_locale' data-analytics-label='pt_PT' href='/focuses/32528955?locale=pt_PT&amp;parent=lti_session' label='português (Portugal)' lang='pt-PT'></ql-menu-item>
<ql-menu-item data-analytics-action='changed_locale' data-analytics-label='ru' href='/focuses/32528955?locale=ru&amp;parent=lti_session' label='русский' lang='ru'></ql-menu-item>
<ql-menu-item data-analytics-action='changed_locale' data-analytics-label='tr' href='/focuses/32528955?locale=tr&amp;parent=lti_session' label='Türkçe' lang='tr'></ql-menu-item>
<ql-menu-item data-analytics-action='changed_locale' data-analytics-label='uk' href='/focuses/32528955?locale=uk&amp;parent=lti_session' label='український' lang='uk'></ql-menu-item>
<ql-menu-item data-analytics-action='changed_locale' data-analytics-label='zh' href='/focuses/32528955?locale=zh&amp;parent=lti_session' label='简体中文' lang='zh'></ql-menu-item>
<ql-menu-item data-analytics-action='changed_locale' data-analytics-label='zh_TW' href='/focuses/32528955?locale=zh_TW&amp;parent=lti_session' label='繁體中文' lang='zh-TW'></ql-menu-item>
</ql-menu>


<ql-icon-button id='my_account' label='My account' tip='My account'>
<ql-avatar src='https://lh3.googleusercontent.com/a/ACg8ocI6s7UhNvX_oCOJMPhLJPmqhqIgwu_5AK0t7wpjF-5jmQo=s320-c'></ql-avatar>
</ql-icon-button>
<ql-menu for='my_account' id='my_account_menu' style='max-height: 640px'>
<div class='my-account-menu'>
<ql-avatar class='l-mtl l-mbl' size='120' src='https://lh3.googleusercontent.com/a/ACg8ocI6s7UhNvX_oCOJMPhLJPmqhqIgwu_5AK0t7wpjF-5jmQo=s320-c'></ql-avatar>
<div class='my-account-menu__user-info l-mbl'>
<h4 class='ql-title-medium'>Justin Ho</h4>
<p class='ql-body-medium text--light'>cliffdove@gmail.com</p>
<p class='ql-body-medium text--light'>
</p>
<a class="text--green ql-title-small" href="/my_account/payments"><ql-chip positive>
0 Credits
</ql-chip>
</a></div>
<div class='buttons l-mbl'>
<a class="button button--hairline" id="settings" href="/my_account/profile">Settings</a>
</div>
<hr>
<ql-button data-analytics-action='clicked_sign_out' href='/users/sign_out' method='delete'>
Sign Out
</ql-button>
<div class='privacy l-mtl'>
<a target="_blank" class="ql-label-medium text--light" href="/privacy_policy">Privacy</a>
<span class='ql-label-medium text--light l-mls l-mrs'>&middot;</span>
<a class="ql-label-medium text--light" href="/terms_of_service">Terms</a>
</div>
</div>
</ql-menu>

</div>
</ql-toolbar>

</div>
</div>

<nav class='nav-panel js-nav-panel'>
<div class='nav-panel__logo'>
<div class="custom-logo">Qwiklabs</div>
</div>
<nav class='ql-sidenav'>
<ql-sidenav-item href='/' icon='home' label='Home'></ql-sidenav-item>

<ql-sidenav-item href='/catalog' icon='school' label='Catalog'></ql-sidenav-item>

<ql-sidenav-item href='/profile' icon='event_note' label='Profile'></ql-sidenav-item>

</nav>

</nav>
<div class='nav-panel__overlay js-nav-toggle'></div>

<main class='js-main' id='jump-content'>
<div class='l-main-wrapper' id='main-wrapper'>




<div class='lab-assessment__tab js-open-lab-assessment-panel'>
<button class='js-lab-assessment-total-score'>
—/25
</button>
</div>
<div aria-labelledby='lab-assessment-checkpoint' class='lab-assessment__panel js-lab-assessment-panel' role='dialog'>
<div class='lab-assessment__panel__header'>
<h4 id='lab-assessment-checkpoint'>Checkpoints</h4>
<ql-icon-button class='js-close-lab-assessment-panel' icon='arrow_forward' label='Close dialog'></ql-icon-button>
</div>
<div class='lab-assessment__step'>
<p class='lab-assessment__step__title' id='lab-assessment-step-title'>
Download a code repository
</p>
<div class='lab-assessment__step__action'>
<ql-button class='js-show-run-step-button' description='Download a code repository' step_no='1'>
Check my progress
</ql-button>
<p class='lab-assessment__step__score'>
<span class='js-assessment-step-score-1'>
</span>
/ 5
</p>
</div>
</div>

<div class='lab-assessment__step'>
<p class='lab-assessment__step__title' id='lab-assessment-step-title'>
Create a BigQuery Dataset
</p>
<div class='lab-assessment__step__action'>
<ql-button class='js-show-run-step-button' description='Create a BigQuery Dataset' step_no='2'>
Check my progress
</ql-button>
<p class='lab-assessment__step__score'>
<span class='js-assessment-step-score-2'>
</span>
/ 5
</p>
</div>
</div>

<div class='lab-assessment__step'>
<p class='lab-assessment__step__title' id='lab-assessment-step-title'>
Simulate traffic sensor data into Pub/Sub
</p>
<div class='lab-assessment__step__action'>
<ql-button class='js-show-run-step-button' description='Simulate traffic sensor data into Pub/Sub' step_no='3'>
Check my progress
</ql-button>
<p class='lab-assessment__step__score'>
<span class='js-assessment-step-score-3'>
</span>
/ 5
</p>
</div>
</div>

<div class='lab-assessment__step'>
<p class='lab-assessment__step__title' id='lab-assessment-step-title'>
Launch Dataflow Pipeline
</p>
<div class='lab-assessment__step__action'>
<ql-button class='js-show-run-step-button' description='Launch Dataflow Pipeline' step_no='4'>
Check my progress
</ql-button>
<p class='lab-assessment__step__score'>
<span class='js-assessment-step-score-4'>
</span>
/ 5
</p>
</div>
</div>

<div class='lab-assessment__step'>
<p class='lab-assessment__step__title' id='lab-assessment-step-title'>
Create an alert
</p>
<div class='lab-assessment__step__action'>
<ql-button class='js-show-run-step-button' description='Create an alert' step_no='5'>
Check my progress
</ql-button>
<p class='lab-assessment__step__score'>
<span class='js-assessment-step-score-5'>
</span>
/ 5
</p>
</div>
</div>

</div>
<ql-drawer-container class='js-lab-state' data-analytics-payload='{&quot;label&quot;:&quot;Streaming Data Processing: Streaming Data Pipelines&quot;,&quot;lab_name&quot;:&quot;Streaming Data Processing: Streaming Data Pipelines&quot;,&quot;classroom_name&quot;:null,&quot;deployment&quot;:&quot;googlecoursera-run&quot;}' data-credits='0.0' data-focus-id='32528955' data-lab-billing-limit='0.0' data-lab-duration='5400' data-parent='lti_session' data-recaptcha-enabled id='lab-container'>
<ql-drawer id='terminal-drawer' slot='drawer'>
<iframe allow='clipboard-read' class='terminal' id='embedded-resource'></iframe>
</ql-drawer>
<ql-drawer-content class='js-lab-wrapper' id='lab-content' slot='drawer-content'>
<ql-drawer-container id='lab-content-container'>
<ql-drawer id='control-panel-drawer' open slot='drawer' width='320'>
<ql-lab-control-panel class='ql-lab-control-panel__max-height control-panel js-lab-control-panel' connectionFiles='[]' labControlButton='{&quot;disabled&quot;:false,&quot;pending&quot;:false,&quot;running&quot;:false}' labDetails='[]' labTimer='{&quot;ticking&quot;:false,&quot;secondsRemaining&quot;:5400}' studentResources='[]'>
<script src="https://www.recaptcha.net/recaptcha/api.js?render=6LeVI8IUAAAAAJNdox5eTkYrw9SbvhZ1TFyv3iHr"   ></script>
        <script>
          // Define function so that we can call it again later if we need to reset it
          // This executes reCAPTCHA and then calls our callback.
          function executeRecaptchaForStartLab() {
            grecaptcha.ready(function() {
              grecaptcha.execute('6LeVI8IUAAAAAJNdox5eTkYrw9SbvhZ1TFyv3iHr', {action: 'start_lab'}).then(function(token) {
                setInputWithRecaptchaResponseTokenForStartLab('g-recaptcha-response-data-start-lab', token)
              });
            });
          };
          // Invoke immediately
          executeRecaptchaForStartLab()

          // Async variant so you can await this function from another async function (no need for
          // an explicit callback function then!)
          // Returns a Promise that resolves with the response token.
          async function executeRecaptchaForStartLabAsync() {
            return new Promise((resolve, reject) => {
             grecaptcha.ready(async function() {
                resolve(await grecaptcha.execute('6LeVI8IUAAAAAJNdox5eTkYrw9SbvhZ1TFyv3iHr', {action: 'start_lab'}))
              });
            })
          };

                  var setInputWithRecaptchaResponseTokenForStartLab = function(id, token) {
          var element = document.getElementById(id);
          if (element !== null) element.value = token;
        }

        </script>
<input type="hidden" name="g-recaptcha-response-data[start_lab]" id="g-recaptcha-response-data-start-lab" data-sitekey="6LeVI8IUAAAAAJNdox5eTkYrw9SbvhZ1TFyv3iHr" class="g-recaptcha g-recaptcha-response "/>

<div aria-live='polite' class='hidden' id='recaptcha-v2-start-lab' slot='recaptcha'>
<script src="https://www.recaptcha.net/recaptcha/api.js" async defer ></script>
<div data-sitekey="6LeOI8IUAAAAAPkHlMAE9NReCD_1WD81iYlBlCnV" data-callback="recaptchaComplete" data-expired-callback="expireV2Token" class="g-recaptcha "></div>
          <noscript>
            <div>
              <div style="width: 302px; height: 422px; position: relative;">
                <div style="width: 302px; height: 422px; position: absolute;">
                  <iframe
                    src="https://www.recaptcha.net/recaptcha/api/fallback?k=6LeOI8IUAAAAAPkHlMAE9NReCD_1WD81iYlBlCnV"
                    name="ReCAPTCHA"
                    style="width: 302px; height: 422px; border-style: none; border: 0; overflow: hidden;">
                  </iframe>
                </div>
              </div>
              <div style="width: 300px; height: 60px; border-style: none;
                bottom: 12px; left: 25px; margin: 0px; padding: 0px; right: 25px;
                background: #f9f9f9; border: 1px solid #c1c1c1; border-radius: 3px;">
                <textarea id="g-recaptcha-response" name="g-recaptcha-response"
                  class="g-recaptcha-response"
                  style="width: 250px; height: 40px; border: 1px solid #c1c1c1;
                  margin: 10px 25px; padding: 0px; resize: none;">
                </textarea>
              </div>
            </div>
          </noscript>

</div>
</ql-lab-control-panel>
</ql-drawer>
<ql-drawer-content id='lab-instructions' slot='drawer-content'>
<div class='lab-content-container'>
<div class='alert alert--fake js-alert'>
<p class='alert__message js-alert-message' role='alert'></p>
<ql-icon-button class='alert__close js-alert-close' icon='clear'></ql-icon-button>
<iframe class='l-ie-iframe-fix' tabindex='-1'></iframe>
</div>
<div class='lab-content__renderable-instructions js-lab-content'>
<div class='lab-preamble'>
<h1 class='lab-preamble__title'>
Streaming Data Processing: Streaming Data Pipelines
</h1>
<div class='lab-preamble__details ql-title-medium'>
<span>1 hour 30 minutes</span>
<span>Free</span>
<div class='lab__rating'>
<a aria-label="Lab Reviews" href="/focuses/32528955/reviews?parent=lti_session"><div class='rateit' data-rateit-readonly='true' data-rateit-value='4.3289'></div>

</a><ql-button aria-label='Rate Lab' id='rate-lab-btn' label='Rate Lab' text></ql-button>
</div>
</div>
</div>
<div class='lab-outline-place-holder'></div>

<div class='markdown-lab-instructions js-markdown-instructions' id='markdown-lab-instructions'>

<h2 id="step1">Overview</h2>
<p>In this lab, you will use Dataflow to collect traffic events from simulated traffic sensor data made available through Google Cloud PubSub, process them into an actionable average, and store the raw data in BigQuery for later analysis. You will learn how to start a Dataflow pipeline, monitor it, and, lastly, optimize it.</p>
<ql-infobox><strong>Note:</strong> At the time of this writing, streaming pipelines are not available in the DataFlow Python SDK. So the streaming labs are written in Java.</ql-infobox>
<h2 id="step2">Objectives</h2>
<p>In this lab, you will perform the following tasks:</p>
<ul>
<li>Launch Dataflow and run a Dataflow job</li>
<li>Understand how data elements flow through the transformations of a Dataflow pipeline</li>
<li>Connect Dataflow to Pub/Sub and BigQuery</li>
<li>Observe and understand how Dataflow autoscaling adjusts compute resources to process input data optimally</li>
<li>Learn where to find logging information created by Dataflow</li>
<li>Explore metrics and create alerts and dashboards with Cloud Monitoring</li>
</ul>
<h2 id="step3">Setup</h2>
<p>For each lab, you get a new Google Cloud project and set of resources for a fixed time at no cost.</p>
<ol>
<li>
<p>Sign in to Qwiklabs using an <strong>incognito window</strong>.</p>
</li>
<li>
<p>Note the lab's access time (for example, <code>1:15:00</code>), and make sure you can finish within that time.<br>
There is no pause feature. You can restart if needed, but you have to start at the beginning.</p>
</li>
<li>
<p>When ready, click <strong>Start lab</strong>.</p>
</li>
<li>
<p>Note your lab credentials (<strong>Username</strong> and <strong>Password</strong>). You will use them to sign in to the Google Cloud Console.</p>
</li>
<li>
<p>Click <strong>Open Google Console</strong>.</p>
</li>
<li>
<p>Click <strong>Use another account</strong> and copy/paste credentials for <strong>this</strong> lab into the prompts.<br>
If you use other credentials, you'll receive errors or <strong>incur charges</strong>.</p>
</li>
<li>
<p>Accept the terms and skip the recovery resource page.</p>
</li>
</ol>
<aside class="warning"><p><strong>Note:</strong> Do not click <strong>End Lab</strong> unless you have finished the lab or want to restart it. This clears your work and removes the project.
  </p>
</aside>

<h3>Check project permissions</h3>
<p>Before you begin your work on Google Cloud, you need to ensure that your project has the correct permissions within Identity and Access Management (IAM).</p>
<ol>
<li>
<p>In the Google Cloud console, on the <strong>Navigation menu</strong> (<img alt="Navigation menu icon" src="https://cdn.qwiklabs.com/tkgw1TDgj4Q%2BYKQUW4jUFd0O5OEKlUMBRYbhlCrF0WY%3D">), select <strong>IAM &amp; Admin</strong> &gt; <strong>IAM</strong>.</p>
</li>
<li>
<p>Confirm that the default compute Service Account <code>{project-number}-compute@developer.gserviceaccount.com</code> is present and has the <code>editor</code> role assigned. The account prefix is the project number, which you can find on <strong>Navigation menu &gt; Cloud Overview &gt; Dashboard</strong>.</p>
</li>
</ol>
<p><img alt="Compute Engine default service account name and editor status highlighted on the Permissions tabbed page" src="https://cdn.qwiklabs.com/1nytD9OUuNUV9undyjUWeOS7LJmekReBDmkUjveCjcU%3D"></p>
<ql-infobox><strong>Note: </strong>If the account is not present in IAM or does not have the <code>editor</code> role, follow the steps below to assign the required role.</ql-infobox>
<ol>
<li>In the Google Cloud console, on the <strong>Navigation menu</strong>, click <strong>Cloud Overview &gt; Dashboard</strong>.</li>
<li>Copy the project number (e.g. <code>729328892908</code>).</li>
<li>On the <strong>Navigation menu</strong>, select <strong>IAM &amp; Admin</strong> &gt; <strong>IAM</strong>.</li>
<li>At the top of the roles table, below <strong>View by Principals</strong>, click <strong>Grant Access</strong>.</li>
<li>For <strong>New principals</strong>, type:</li>
</ol>
<ql-code-block language="plaintext">
  {project-number}-compute@developer.gserviceaccount.com
</ql-code-block>
<ol start="6">
<li>Replace <code>{project-number}</code> with your project number.</li>
<li>For <strong>Role</strong>, select <strong>Project</strong> (or Basic) &gt; <strong>Editor</strong>.</li>
<li>Click <strong>Save</strong>.</li>
</ol>

<h2 id="step4">Task 1. Preparation</h2>
<p>You will be running a sensor simulator from the training VM. In Lab 1 you manually setup the Pub/Sub components. In this lab several of those processes are automated.</p>
<h3>Open the SSH terminal and connect to the training VM</h3>
<ol>
<li>
<p>In the Console, on the <strong>Navigation menu</strong> (<img alt="Navigation menu icon" src="https://cdn.qwiklabs.com/tkgw1TDgj4Q%2BYKQUW4jUFd0O5OEKlUMBRYbhlCrF0WY%3D">), click <strong>Compute engine</strong> &gt; <strong>VM instances</strong>.</p>
</li>
<li>
<p>Locate the line with the instance called <strong>training-vm</strong>.</p>
</li>
<li>
<p>On the far right, under <strong>Connect</strong>, click on <strong>SSH</strong> to open a terminal window.</p>
</li>
<li>
<p>In this lab, you will enter CLI commands on the <strong>training-vm</strong>.</p>
</li>
</ol>
<h3><strong>Verify initialization is complete</strong></h3>
<p>The <strong>training-vm</strong> is installing some software in the background.</p>
<ul>
<li>Verify that setup is complete by checking the contents of the new directory:</li>
</ul>
<ql-code-block language="plaintext">
ls /training
</ql-code-block>
<p>The setup is complete when the result of your list (ls) command output appears as in the image below. If the full listing does not appear, wait a few minutes and try again.</p>
<p><img alt="VM Folder" src="https://cdn.qwiklabs.com/QUdNzIpyaubibm%2FC1LDE8A1142yMMBos0HckMq8SDJI%3D"></p>
<ql-infobox><strong>Note:</strong> It may take 2 to 3 minutes for all background actions to complete.</ql-infobox>
<h3><strong>Download code repository</strong></h3>
<ul>
<li>Next you will refresh the code repository for use in this lab:</li>
</ul>
<ql-code-block language="plaintext">
git clone https://github.com/GoogleCloudPlatform/training-data-analyst
</ql-code-block>
<h3>Set environment variables</h3>
<ul>
<li>On the <strong>training-vm</strong> SSH terminal enter the following:</li>
</ul>
<ql-code-block language="plaintext">
source /training/project_env.sh
</ql-code-block>
<p>This script sets the <code>DEVSHELL_PROJECT_ID</code> and <code>BUCKET</code> environment variables.</p>
<p>Click <strong>Check my progress</strong> to verify the objective.
<ql-activity-tracking step="1">
Download a code repository
</ql-activity-tracking></p>
<h2 id="step5">Task 2. Create a BigQuery dataset and Cloud Storage bucket</h2>
<p>The Dataflow pipeline will be created later and written into a table in the BigQuery dataset.</p>
<h3>Open BigQuery Console</h3>
<ol>
<li>In the Google Cloud Console, select <strong>Navigation menu</strong> &gt; <strong>BigQuery</strong>.</li>
</ol>
<p>The <strong>Welcome to BigQuery in the Cloud Console</strong> message box opens. This message box provides a link to the quickstart guide and lists UI updates.</p>
<ol start="2">
<li>Click <strong>Done</strong>.</li>
</ol>

<h3>Create a BigQuery dataset</h3>
<ol>
<li>
<p>To create a dataset, click on the <strong>View actions</strong> icon next to your project ID and select <strong>Create dataset</strong>.</p>
</li>
<li>
<p>Next, name your Dataset ID <code>demos</code> and leave all other options at their default values, and then click <strong>Create dataset</strong>.</p>
</li>
</ol>
<h3>Verify the Cloud Storage bucket</h3>
<p>A bucket should already exist that has the same name as the Project ID.</p>
<ol>
<li>
<p>In the Console, on the <strong>Navigation menu</strong> (<img alt="Navigation menu icon" src="https://cdn.qwiklabs.com/tkgw1TDgj4Q%2BYKQUW4jUFd0O5OEKlUMBRYbhlCrF0WY%3D">), click <strong>Cloud Storage</strong> &gt; <strong>Buckets</strong>.</p>
</li>
<li>
<p>Observe the following values:</p>
</li>
</ol>
<table>
<tr>
<td colspan="1" rowspan="1">
<p><strong>Property</strong></p>
</td>
<td colspan="1" rowspan="1">
<p><strong>Value</strong></p>
<p>(type value or select option as specified)</p>
</td>
</tr>
<tr>
<td colspan="1" rowspan="1">
<p><strong>Name</strong></p>
</td>
<td colspan="1" rowspan="1">
<p><strong><ql-variable key="project_0.project_id" placeholder="PROJECT ID"></ql-variable></strong></p>
</td>
</tr>
<tr>
<td colspan="1" rowspan="1">
<p><strong>Default storage class</strong></p>
</td>
<td colspan="1" rowspan="1">
<p><strong>Regional</strong></p>
</td>
</tr>
<tr>
<td colspan="1" rowspan="1">
<p><strong>Location</strong></p>
</td>
<td colspan="1" rowspan="1">
<p><strong><ql-variable key="project_0.startup_script.gcp_region" placeholder="Lab GCP Region"></ql-variable></strong></p>
</td>
</tr>
</table>
<p>Click <strong>Check my progress</strong> to verify the objective.
<ql-activity-tracking step="2">
Create a BigQuery Dataset
</ql-activity-tracking></p>
<h2 id="step6">Task 3. Simulate traffic sensor data into Pub/Sub</h2>
<ul>
<li>In the <strong>training-vm</strong> SSH terminal, start the sensor simulator. The script reads sample data from a CSV file and publishes it to Pub/Sub:</li>
</ul>
<ql-code-block language="plaintext">
/training/sensor_magic.sh
</ql-code-block>
<p>This command will send 1 hour of data in 1 minute.  Let the script continue to run in the current terminal.</p>
<h3>Open a second SSH terminal and connect to the training VM</h3>
<ol>
<li>
<p>In the upper right corner of the <strong>training-vm</strong> SSH terminal, click on the gear-shaped button (<img alt="Settings icon" src="https://cdn.qwiklabs.com/5l7QbWP0MNGiSAzlNwx5cgtBTOs7l%2BEp155GRJm6SZE%3D">) and select <strong>New Connection to training-vm</strong> from the drop-down menu. A new terminal window will open.</p>
</li>
<li>
<p>The new terminal session will not have the required environment variables. Run the following command to set them.</p>
</li>
<li>
<p>In the new <strong>training-vm</strong> SSH terminal enter the following:</p>
</li>
</ol>
<ql-code-block language="plaintext">
source /training/project_env.sh
</ql-code-block>
<p>Click <strong>Check my progress</strong> to verify the objective.
<ql-activity-tracking step="3">
Simulate traffic sensor data into Pub/Sub
</ql-activity-tracking></p>
<h2 id="step7">Task 4. Launch Dataflow pipeline</h2>
<h3>Verify that Google Cloud Dataflow API is enabled for this project</h3>
<ol>
<li>To ensure that the proper APIs and permissions are set, execute the following block of code in the Cloud Shell.</li>
</ol>
<ql-code-block templated="">
gcloud services disable dataflow.googleapis.com --force
gcloud services enable dataflow.googleapis.com
</ql-code-block>
<ol start="2">
<li>Return to the second <strong>training-vm</strong> SSH terminal. Change into the directory for this lab.</li>
</ol>
<ql-code-block language="plaintext">
cd ~/training-data-analyst/courses/streaming/process/sandiego
</ql-code-block>
<ol start="3">
<li>Identify the script that creates and runs the Dataflow pipeline.</li>
</ol>
<ql-code-block language="plaintext">
cat run_oncloud.sh
</ql-code-block>
<ol start="4">
<li>Copy-and-paste the following URL into a new browser tab to view the source code on Github:</li>
</ol>
<ql-code-block language="plaintext">
https://github.com/GoogleCloudPlatform/training-data-analyst/blob/master/courses/streaming/process/sandiego/run_oncloud.sh
</ql-code-block>
<ol start="5">
<li>The script requires three arguments: <strong>project id</strong>, <strong>bucket name</strong>, <strong>classname</strong>
</li>
</ol>
<p>A 4th optional argument is <strong>options</strong>. The <strong>options</strong> argument discussed later in this lab.</p>
<table>
<tr>
<td colspan="1" rowspan="1">
<p><strong>project id</strong></p>
</td>
<td colspan="1" rowspan="1">
<p><code><ql-variable key="project_0.project_id" placeholder="PROJECT ID"></ql-variable></code></p>
</td>
</tr>
<tr>
<td colspan="1" rowspan="1">
<p><strong>bucket name</strong></p>
</td>
<td colspan="1" rowspan="1">
<p><code><ql-variable key="project_0.project_id" placeholder="Bucket Name"></ql-variable></code></p>
</td>
</tr>
<tr>
<td colspan="1" rowspan="1">
<p><strong>classname</strong></p>
</td>
<td colspan="1" rowspan="1">
<p><code>&lt;java file that runs aggregations&gt;</code></p>
</td>
</tr>
<tr>
<td colspan="1" rowspan="1">
<p><strong>options</strong></p>
</td>
<td colspan="1" rowspan="1">
<p><code>&lt;options&gt;</code></p>
</td>
</tr>
</table>
<p>There are 4 java files that you can choose from for <strong>classname</strong>.  Each reads the traffic data from Pub/Sub and runs different aggregations/computations.</p>
<ol start="6">
<li>Go into the java directory. Identify the source file <strong>AverageSpeeds.java</strong>.</li>
</ol>
<ql-code-block language="plaintext">
cd ~/training-data-analyst/courses/streaming/process/sandiego/src/main/java/com/google/cloud/training/dataanalyst/sandiego

cat AverageSpeeds.java
</ql-code-block>
<p>What does the script do?</p>
<p>Close the file to continue. You will want to refer to this source code while running the application. So for easy access you will open a new browser tab and view the file <strong>AverageSpeeds.java</strong> on Github.</p>
<ol start="7">
<li>Copy-and-paste the following URL into a browser tab to view the source code on Github:</li>
</ol>
<ql-code-block language="plaintext">
https://github.com/GoogleCloudPlatform/training-data-analyst/blob/master/courses/streaming/process/sandiego/src/main/java/com/google/cloud/training/dataanalyst/sandiego/AverageSpeeds.java
</ql-code-block>
<p>Leave this browser tab open. You will be referring back to the source code in a later step in this lab.</p>
<ol start="8">
<li>Return to the <strong>training-vm</strong> SSH terminal. Run the following commands for the Dataflow pipeline to read from PubSub and write into BigQuery:</li>
</ol>
<ql-code-block templated="">
cd ~/training-data-analyst/courses/streaming/process/sandiego
export REGION={{{project_0.startup_script.gcp_region|Lab GCP Region}}}
</ql-code-block>
<ql-code-block language="plaintext">
./run_oncloud.sh $DEVSHELL_PROJECT_ID $BUCKET AverageSpeeds
</ql-code-block>
<p>This script uses maven to build a Dataflow streaming pipeline in Java.</p>
<p>Example successful completion:</p>
<ql-code-block output="">
[INFO] ------------------------------------------------------------------------
[INFO] BUILD SUCCESS
[INFO] ------------------------------------------------------------------------
[INFO] Total time: 45.542 s
[INFO] Finished at: 2018-06-08T16:51:30+00:00
[INFO] Final Memory: 56M/216M
[INFO] ------------------------------------------------------------------------
</ql-code-block>
<h2 id="step8">Task 5. Explore the pipeline</h2>
<p>This Dataflow pipeline reads messages from a Pub/Sub topic, parses the JSON of the input message, produces one main output and writes to BigQuery.</p>
<ol>
<li>Return to the browser tab for Console. On the <strong>Navigation menu</strong> (<img alt="Navigation menu icon" src="https://cdn.qwiklabs.com/tkgw1TDgj4Q%2BYKQUW4jUFd0O5OEKlUMBRYbhlCrF0WY%3D">), click <strong>Dataflow</strong> and click on your job to monitor progress.</li>
</ol>
<p>Example:</p>
<p><img alt="Dataflow job monitoring window" src="https://cdn.qwiklabs.com/5tVtB953BMyju7QibzMmH6S%2FwN29CBAwD9X2wEgEqEc%3D"></p>
<ql-infobox><strong>Note:</strong> If Dataflow Job failed, run the command <code>./run_oncloud.sh $DEVSHELL_PROJECT_ID $BUCKET AverageSpeeds</code> again.</ql-infobox>
<ol start="2">
<li>
<p>After the pipeline is running, click on the <strong>Navigation menu</strong> (<img alt="Navigation menu icon" src="https://cdn.qwiklabs.com/tkgw1TDgj4Q%2BYKQUW4jUFd0O5OEKlUMBRYbhlCrF0WY%3D">), click <strong>Pub/Sub</strong> &gt; <strong>Topics</strong>.</p>
</li>
<li>
<p>Examine the line for <strong>Topic name</strong> for the topic <strong>sandiego</strong>.</p>
</li>
<li>
<p>Return to the <strong>Navigation menu</strong> (<img alt="Navigation menu icon" src="https://cdn.qwiklabs.com/tkgw1TDgj4Q%2BYKQUW4jUFd0O5OEKlUMBRYbhlCrF0WY%3D">), click <strong>Dataflow</strong> and click on your job.</p>
</li>
<li>
<p>Compare the code in the Github browser tab, <strong>AverageSpeeds.java</strong> and the pipeline graph on the page for your Dataflow job.</p>
</li>
<li>
<p>Find the <strong>GetMessages</strong> pipeline step in the graph, and then find the corresponding code in the <strong>AverageSpeeds.java</strong> file. This is the pipeline step that reads from the Pub/Sub topic. It creates a collection of Strings - which corresponds to Pub/Sub messages that have been read.</p>
</li>
</ol>
<ul>
<li>Do you see a subscription created?</li>
<li>How does the code pull messages from Pub/Sub?</li>
</ul>
<ol start="7">
<li>Find the <strong>Time Window</strong> pipeline step in the graph and in code. In this pipeline step we create a window of a duration specified in the pipeline parameters (sliding window in this case). This window will accumulate the traffic data from the previous step until end of window, and pass it to the next steps for further transforms.</li>
</ol>
<ul>
<li>What is the window interval?</li>
<li>How often is a new window created?</li>
</ul>
<ol start="8">
<li>
<p>Find the <strong>BySensor</strong> and <strong>AvgBySensor</strong> pipeline steps in the graph, and then find the corresponding code snippet in the AverageSpeeds.java file. This <strong>BySensor</strong> does a grouping of all events in the window by sensor id, while <strong>AvgBySensor</strong> will then compute the mean speed for each grouping.</p>
</li>
<li>
<p>Find the <strong>ToBQRow</strong> pipeline step in the graph and in code. This step simply creates a "row" with the average computed from the previous step together with the lane information.</p>
</li>
</ol>
<ql-infobox><strong>Note:</strong> In practice, other actions could be taken in the <strong>ToBQRow</strong> step. For example, it could compare the calculated mean against a predefined threshold and log the results of the comparison in Cloud Logging.</ql-infobox>
<ol start="10">
<li>
<p>Find the <strong>BigQueryIO.Write</strong> in both the pipeline graph and in the source code. This step writes the row out of the pipeline into a BigQuery table. Because we chose the <strong>WriteDisposition.WRITE_APPEND</strong> write disposition, new records will be appended to the table.</p>
</li>
<li>
<p>Return to the BigQuery web UI tab. Refresh your browser.</p>
</li>
<li>
<p>Find your project name and the demos dataset you created. The small arrow to the left of the dataset name <strong>demos</strong> should now be active and clicking on it will reveal the  <strong>average_speeds</strong> table.</p>
</li>
<li>
<p>It will take several minutes before the <strong>average_speeds</strong> table appears in BigQuery.</p>
</li>
</ol>
<p>Example:</p>
<p><img alt="New averagespeeds table displays" src="https://cdn.qwiklabs.com/AQ%2F6RAXQQLidJi%2BGJ976MrpD9DeIDJbo%2F4IbbTUCwbk%3D"></p>
<p>Click <strong>Check my progress</strong> to verify the objective.
<ql-activity-tracking step="4">
Launch Dataflow Pipeline
</ql-activity-tracking></p>
<h2 id="step9">Task 6. Determine throughput rates</h2>
<p>One common activity when monitoring and improving Dataflow pipelines is figuring out how many elements the pipeline processes per second, what the system lag is, and how many data elements have been processed so far. In this activity you will learn where in the Cloud Console one can find information about processed elements and time.</p>
<ol>
<li>
<p>Return to the browser tab for Console. On the <strong>Navigation menu</strong> (<img alt="Navigation menu icon" src="https://cdn.qwiklabs.com/tkgw1TDgj4Q%2BYKQUW4jUFd0O5OEKlUMBRYbhlCrF0WY%3D">), click <strong>Dataflow</strong> and click on your job to monitor progress (it will have your username in the pipeline name).</p>
</li>
<li>
<p>Select the <strong>GetMessages</strong> pipeline node in the graph and look at the step metrics on the right.</p>
</li>
</ol>
<ul>
<li>
<strong>System Lag</strong> is an important metric for streaming pipelines. It represents the amount of time data elements are waiting to be processed since they "arrived" in the input of the transformation step.</li>
<li>
<strong>Elements Added</strong> metric under output collections tells you how many data elements exited this step (for the <strong>Read PubSub Msg</strong> step of the pipeline it also represents the number of Pub/Sub messages read from the topic by the Pub/Sub IO connector).</li>
</ul>
<ol start="3">
<li>Select the <strong>Time Window</strong> node in the graph. Observe how the Elements Added metric under the Input Collections of the <strong>Time Window</strong> step matches the Elements Added metric under the Output Collections of the previous step <strong>GetMessages</strong>.</li>
</ol>
<h2 id="step10">Task 7. Review BigQuery output</h2>
<ol>
<li>Return to the BigQuery web UI.</li>
</ol>
<ql-infobox><strong>Note:</strong> Streaming data and tables may not show up immediately, and the Preview feature may not be available for data that is still in the streaming buffer.<p></p> If you click on <strong>Preview</strong> you will see the message "This table has records in the streaming buffer that may not be visible in the preview." You can still run queries to view the data.</ql-infobox>
<ol start="2">
<li>In the <strong>Query editor</strong> window, type (or copy-and-paste) the following query. Use the following query to observe the output from the Dataflow job.  Click <strong>Run</strong>:</li>
</ol>
<ql-code-block language="sql">
SELECT *
FROM `demos.average_speeds`
ORDER BY timestamp DESC
LIMIT 100
</ql-code-block>
<ol start="3">
<li>Find the last update to the table by running the following SQL:</li>
</ol>
<ql-code-block language="sql">
SELECT
MAX(timestamp)
FROM
`demos.average_speeds`
</ql-code-block>
<ol start="4">
<li>Next use the time travel capability of BigQuery to reference the state of the table at a previous point in time.</li>
</ol>
<p>The query below will return a subset of rows from the <strong>average_speeds</strong> table that existed at 10 minutes ago.</p>
<p>If your query requests rows but the table did not exist at the reference point in time, you will receive the following error message:</p>
<p><code>Invalid snapshot time 1633691170651 for Table PROJECT:DATASET.TABLE__</code></p>
<p>If you encounter this error please reduce the scope of your time travel by lowering the minute value:</p>
<ql-code-block language="sql">
SELECT *
FROM `demos.average_speeds`
FOR SYSTEM_TIME AS OF TIMESTAMP_SUB(CURRENT_TIMESTAMP, INTERVAL 10 MINUTE)
ORDER BY timestamp DESC
LIMIT 100
</ql-code-block>
<h2 id="step11">Task 8. Observe and understand autoscaling</h2>
<p>Observe how Dataflow scales the number of workers to process the backlog of incoming Pub/Sub messages.</p>
<ol>
<li>
<p>Return to the browser tab for Console. On the <strong>Navigation menu</strong> (<img alt="Navigation menu icon" src="https://cdn.qwiklabs.com/tkgw1TDgj4Q%2BYKQUW4jUFd0O5OEKlUMBRYbhlCrF0WY%3D">), click <strong>Dataflow</strong> and click on your pipeline job.</p>
</li>
<li>
<p>Examine the <strong>Job metrics</strong> panel on the right, and review the <strong>Autoscaling</strong> section. How many workers are currently being used to process messages in the Pub/Sub topic?</p>
</li>
<li>
<p>Click on <strong>More history</strong> and review how many workers were used at different points in time during pipeline execution.</p>
</li>
<li>
<p>The data from a traffic sensor simulator started at the beginning of the lab creates hundreds of messages per second in the Pub/Sub topic.  This will cause Dataflow to increase the number of workers to keep the system lag of the pipeline at optimal levels.</p>
</li>
<li>
<p>Click on <strong>More history</strong>. In the <strong>Worker pool</strong>, you can see how Dataflow changed the number of workers. Notice the <strong>Status</strong> column that explains the reason for the change.</p>
</li>
</ol>
<p><img alt="Dataflow job details" src="https://cdn.qwiklabs.com/Qeuf5VZOsDS08iB8pAvnW4EGzqp%2FJ%2FY10nQbSEPeVNo%3D"></p>
<h2 id="step12">Task 9. Refresh the sensor data simulation script</h2>
<ql-infobox><strong>Note:</strong> The training lab environment has quota limits. If the sensor data simulation script runs too long it will pass a quota limit, causing the session credentials to be suspended.</ql-infobox>
<ol>
<li>
<p>Return to the <strong>training-vm</strong> SSH terminal where the sensor data script is running.</p>
</li>
<li>
<p>If you see messages that say <strong>INFO: Publishing</strong> then the script is still running. Press CRTL+C to stop it. Then issue the command to start the script again:</p>
</li>
</ol>
<ql-code-block language="plaintext">
cd ~/training-data-analyst/courses/streaming/publish

./send_sensor_data.py --speedFactor=60 --project $DEVSHELL_PROJECT_ID
</ql-code-block>
<ql-warningbox>The following steps 3-8 are only necessary if you are not able to use CTRL+C to stop the script. If the script has passed the quota limit, you will see repeating error messages that "credentials could not be refreshed" and CTRL+C will not work. In this case, simply close the SSH terminal and follow steps 3-8 below.</ql-warningbox>
<ol start="3">
<li>
<p>Open a new SSH terminal. The new session will have a fresh quota.</p>
</li>
<li>
<p>In the Console, on the <strong>Navigation menu</strong> (<img alt="Navigation menu icon" src="https://cdn.qwiklabs.com/tkgw1TDgj4Q%2BYKQUW4jUFd0O5OEKlUMBRYbhlCrF0WY%3D">), click <strong>Compute Engine</strong> &gt; <strong>VM instances</strong>.</p>
</li>
<li>
<p>Locate the line with the instance called <strong>training-vm</strong>.</p>
</li>
<li>
<p>On the far right, under <strong>Connect</strong>, click on <strong>SSH</strong> to open a new terminal window.</p>
</li>
<li>
<p>In the <strong>training-vm</strong> SSH terminal, enter the following to create environment variables:</p>
</li>
</ol>
<ql-code-block language="plaintext">
source /training/project_env.sh
</ql-code-block>
<ol start="8">
<li>Use the following commands to start a new sensor simulator:</li>
</ol>
<ql-code-block language="plaintext">
cd ~/training-data-analyst/courses/streaming/publish

./send_sensor_data.py --speedFactor=60 --project $DEVSHELL_PROJECT_ID
</ql-code-block>
<h2 id="step13">Task 10. Cloud Monitoring integration</h2>
<p>Cloud Monitoring integration with Dataflow allows users to access Dataflow job metrics such as System Lag (for streaming jobs), Job Status (Failed, Successful), Element Counts, and User Counters from within Cloud Monitoring.</p>
<h3>Integration features of Cloud Monitoring</h3>
<ul>
<li>
<strong>Explore Dataflow Metrics</strong>: Browse through available Dataflow pipeline metrics and visualize them in charts.</li>
</ul>
<p>Some common Dataflow metrics.</p>
<table>

<tr>
<th>Metrics</th>
<th>Features</th>
</tr>


<tr>
<td><strong>Job status</strong></td>
<td>Job status (Failed, Successful), reported as an enum every 30 secs and on update.</td>
</tr>
<tr>
<td><strong>Elapsed time</strong></td>
<td>Job elapsed time (measured in seconds), reported every 30 secs.</td>
</tr>
<tr>
<td><strong>System lag</strong></td>
<td>Max lag across the entire pipeline, reported in seconds.</td>
</tr>
<tr>
<td><strong>Current vCPU count</strong></td>
<td>Current # of virtual CPUs used by the job and updated on value change.</td>
</tr>
<tr>
<td><strong>Estimated byte count</strong></td>
<td>Number of bytes processed per PCollection.</td>
</tr>

</table>
<ul>
<li>
<strong>Chart Dataflow metrics in Monitoring Dashboards</strong>: Create Dashboards and chart time series of Dataflow metrics.</li>
<li>
<strong>Configure Alerts</strong>: Define thresholds on job or resource group-level metrics and alert when these metrics reach specified values. Monitoring alerts notify on a variety of conditions such as long streaming system lag or failed jobs.</li>
<li>
<strong>Monitor User-Defined Metrics</strong>: In addition to Dataflow metrics, Dataflow exposes user-defined metrics (SDK Aggregators) as Monitoring custom counters in the Monitoring UI, available for charting and alerting. Any Aggregator defined in a Dataflow pipeline will be reported to Monitoring as a custom metric. Dataflow will define a new custom metric on behalf of the user and report incremental updates to Monitoring approximately every 30 seconds.</li>
</ul>
<h2 id="step14">Task 11. Explore metrics</h2>
<p>Cloud monitoring is a separate service in Google Cloud. So you will need to go through some setup steps to initialize the service for your lab account.</p>
<h3>Create a Monitoring workspace</h3>
<p>You will now setup a Monitoring workspace that's tied to your Google Cloud Project. The following steps create a new account that has a free trial of Monitoring.</p>
<ol>
<li>
<p>In the Cloud Console, click on <strong>Navigation menu</strong> &gt; <strong>Monitoring</strong>.</p>
</li>
<li>
<p>Wait for your workspace to be provisioned.</p>
</li>
</ol>
<p>When the Monitoring dashboard opens, your workspace is ready.</p>
<p><img alt="The Monitoring dashboard open on the Overview page" src="https://cdn.qwiklabs.com/58FQA3ZYeF1Uh01sWQnh5ymX4wPAAjryBAbPh92DHsY%3D"></p>

<ol start="3">
<li>
<p>In the panel to the left click on <strong>Metrics explorer</strong>.</p>
</li>
<li>
<p>In the Metrics Explorer, under <strong>Resource &amp; Metric</strong> click on <strong>Select a metric</strong>.</p>
</li>
<li>
<p>Select <code>Dataflow Job &gt; Job</code> You should see a list of available Dataflow-related metrics. Select <strong>Data watermark lag</strong> and click <strong>Apply</strong>.</p>
</li>
<li>
<p>Cloud monitoring will draw a graph on the right side of the page.</p>
</li>
<li>
<p>Under metric, click on the <strong>Reset</strong> to remove the <strong>Data watermark lag</strong> metric. Select a new dataflow metric <strong>System lag</strong>.</p>
</li>
</ol>
<ql-infobox><p><strong>Note:</strong> The metrics that Dataflow provides to Monitoring are listed in the <a href="https://cloud.google.com/monitoring/api/metrics_gcp" target="blank">Google Cloud metrics documentation</a>. You can search on the page for Dataflow. The metrics you have viewed are useful indicators of pipeline performance.</p>
<p></p>
<strong>Data watermark lag:</strong> The age (time since event timestamp) of the most recent item of data that has been fully processed by the pipeline.<p></p>
<strong>System lag: </strong>The current maximum duration that an item of data has been awaiting processing, in seconds.</ql-infobox>
<h2 id="step15">Task 12. Create alerts</h2>
<p>If you want to be notified when a certain metric crosses a specified threshold (for example, when System Lag of our lab streaming pipeline increases above a predefined value), you could use the Alerting mechanisms of Monitoring to accomplish that.</p>
<h3>Create an alert</h3>
<ol>
<li>
<p>On the Cloud Monitoring, click <strong>Alerting</strong>.</p>
</li>
<li>
<p>Click <strong>+ Create policy</strong>.</p>
</li>
<li>
<p>Click on <strong>Select a metric</strong> dropdown. Disable the <strong>Show only active resources &amp; metrics</strong>.</p>
</li>
<li>
<p>Type <strong>Dataflow Job</strong> in filter by resource and metric name and click on <strong>Dataflow Job &gt; Job</strong>. Select <code>System Lag</code> and click <strong>Apply</strong>.</p>
</li>
<li>
<p>Click <strong>Configure Trigger</strong>.</p>
</li>
<li>
<p>Set the <strong>Threshold position</strong> to <code>Above threshold</code>, <strong>Threshold value</strong> to <code>5</code> and <strong>Advanced options &gt; Retest window</strong> to <code>1 min</code>. Click <strong>Next</strong>.</p>
</li>
</ol>
<h3>Add a notification</h3>
<ol>
<li>Click on the drop down arrow next to <strong>Notification channels</strong>, then click on <strong>Manage notification channels</strong>.</li>
</ol>
<p>A <strong>Notification channels</strong> page will open in a new tab.</p>
<ol start="2">
<li>
<p>Scroll down the page and click on <strong>Add new</strong> for <strong>Email</strong>.</p>
</li>
<li>
<p>In the <strong>Create email channel</strong>  dialog box, enter the lab username as the <strong>Email address</strong> field and a <strong>Display name</strong>.</p>
</li>
</ol>
<ql-warningbox><strong>Note:</strong> If you enter your own email address, you might get alerts until all the resources in the project have been deleted.</ql-warningbox>
<ol start="4">
<li>
<p>Click <strong>Save</strong>.</p>
</li>
<li>
<p>Go back to the previous <strong>Create alerting policy</strong> tab.</p>
</li>
<li>
<p>Click on <strong>Notification channels</strong> again, then click on the <strong>Refresh icon</strong> to get the display name you mentioned in the previous step.</p>
</li>
<li>
<p>Now, select your <strong>Display name</strong> and click <strong>OK</strong>.</p>
</li>
<li>
<p>Set <strong>Alert name</strong> as <code>MyAlertPolicy</code>.</p>
</li>
<li>
<p>Click <strong>Next</strong>.</p>
</li>
<li>
<p>Review the alert and click <strong>Create policy</strong>.</p>
</li>
</ol>
<h3>View events</h3>
<ol>
<li>
<p>On the Cloud Monitoring tab, click on <strong>Alerting &gt; Policies</strong>.</p>
</li>
<li>
<p>Every time an alert is triggered by a Metric Threshold condition, an Incident and a corresponding Event are created in Monitoring. If you specified a notification mechanism in the alert (email, SMS, pager, etc), you will also receive a notification.</p>
</li>
</ol>
<p>Click <strong>Check my progress</strong> to verify the objective.
<ql-activity-tracking step="5">
Create an alert
</ql-activity-tracking></p>
<h2 id="step16">Task 13. Set up dashboards</h2>
<p>You can easily build dashboards with the most relevant Dataflow-related charts with Cloud Monitoring Dashboards.</p>
<ol>
<li>
<p>In the left pane, click  <strong>Dashboards</strong>.</p>
</li>
<li>
<p>Click <strong>+Create dashboard</strong>.</p>
</li>
<li>
<p>For <strong>New dashboard name</strong>, type <code>My Dashboard</code>.</p>
</li>
<li>
<p>Click <strong>Add Widget</strong>, then <strong>Line chart</strong>.</p>
</li>
<li>
<p>Click on the <code>dropdown</code> box under <strong>Resource &amp; Metric</strong>.</p>
</li>
<li>
<p>Select <code>Dataflow Job &gt; Job &gt; System Lag</code> and click <strong>Apply</strong>.</p>
</li>
<li>
<p>In the <strong>Filters</strong> panel, click <strong>+ Add filter</strong>.</p>
</li>
<li>
<p>Select <strong>project_id</strong> in the <code>Label</code> field, then select or type your <strong><ql-variable key="project_0.project_id" placeholder="GCP Project Id"></ql-variable></strong> in the <code>Value</code> field.</p>
</li>
<li>
<p>Click <strong>Apply</strong>.</p>
</li>
</ol>
<p>Example:</p>
<p><img alt="Example dashboard screenshot" src="https://cdn.qwiklabs.com/UaChWbZd5SY5J5TsPHSLrHI2e%2Fb5Mx4rXYmO%2Bw7rO58%3D"></p>
<p>You can add more charts to the dashboard, if you would like, for example, Pub/Sub publish rates on the topic, or subscription backlog (which is a signal to the Dataflow auto-scaler).</p>
<h2 id="step17">End your lab</h2>
<p>When you have completed your lab, click <strong>End Lab</strong>. Google Cloud Skills Boost removes the resources you’ve used and cleans the account for you.</p>
<p>You will be given an opportunity to rate the lab experience. Select the applicable number of stars, type a comment, and then click <strong>Submit</strong>.</p>
<p>The number of stars indicates the following:</p>
<ul>
<li>1 star = Very dissatisfied</li>
<li>2 stars = Dissatisfied</li>
<li>3 stars = Neutral</li>
<li>4 stars = Satisfied</li>
<li>5 stars = Very satisfied</li>
</ul>
<p>You can close the dialog box if you don't want to provide feedback.</p>
<p>For feedback, suggestions, or corrections, please use the <strong>Support</strong> tab.</p>

<p>Copyright 2022 Google LLC All rights reserved. Google and the Google logo are trademarks of Google LLC. All other company and product names may be trademarks of the respective companies with which they are associated.</p>





</div>
</div>


<div class='lab-content__end-lab-button js-end-lab-button-container hidden'>
<ql-lab-control-button class='js-end-lab-button' running></ql-lab-control-button>
</div>
<!-- / TODO: Move recommendations into the end lab modal -->
</div>
<div aria-label='Lab Table of Contents' class='outline-container' id='js-outline-container' role='navigation'>
<ul class='lab-content__outline js-lab-content-outline'>
<li><a href="#step1">Overview</a></li><li><a href="#step2">Objectives</a></li><li><a href="#step3">Setup</a></li><li><a href="#step4">Task 1. Preparation</a></li><li><a href="#step5">Task 2. Create a BigQuery dataset and Cloud Storage bucket</a></li><li><a href="#step6">Task 3. Simulate traffic sensor data into Pub/Sub</a></li><li><a href="#step7">Task 4. Launch Dataflow pipeline</a></li><li><a href="#step8">Task 5. Explore the pipeline</a></li><li><a href="#step9">Task 6. Determine throughput rates</a></li><li><a href="#step10">Task 7. Review BigQuery output</a></li><li><a href="#step11">Task 8. Observe and understand autoscaling</a></li><li><a href="#step12">Task 9. Refresh the sensor data simulation script</a></li><li><a href="#step13">Task 10. Cloud Monitoring integration</a></li><li><a href="#step14">Task 11. Explore metrics</a></li><li><a href="#step15">Task 12. Create alerts</a></li><li><a href="#step16">Task 13. Set up dashboards</a></li><li><a href="#step17">End your lab</a></li>
</ul>
</div>
</ql-drawer-content>
</ql-drawer-container>
</ql-drawer-content>
</ql-drawer-container>
<ql-snackbar id='alert-snackbar'></ql-snackbar>



</div>
</main>

<span class='hidden' id='flash-sibling-before'></span>
<ql-snackbar></ql-snackbar>

<script data-glue-cookie-notification-bar-category='2B' src='https://www.gstatic.com/glue/cookienotificationbar/cookienotificationbar.min.js'></script>

<ql-dialog headline='Score Details' icon='task_alt' id='jupyter-feedback-modal'>
<iframe id='jupyter-feedback-frame' srcdoc='' title='Jupyter Feedback'></iframe>
</ql-dialog>

<div class='modal fade' id='lab-details-modal'>
<div class='modal-container'>
<div class='modal-content mdl-shadow--24dp'>
<div class='modal-body'>
<p class='l-mbm'>
Streaming Data Processing: Streaming Data Pipelines
</p>
<p class='small-label l-mbs'>
<strong>
Duration:
</strong>
1m setup
&middot;
90m access
&middot;
90m completion
</p>
<p class='small-label l-mbs'>
<strong>AWS Region:</strong>
[] <strong></strong>
</p>
<p class='small-label l-mbs'>
<span><strong>Levels: </strong>fundamental</span>
</p>
<p class='small-label'>
<strong>
Permalink:
</strong>
<a href="https://googlecoursera.qwiklabs.com/catalog_lab/2187">https://googlecoursera.qwiklabs.com/catalog_lab/2187</a>
</p>
</div>
<div class='modal-actions'>
<a class='button button--text' data-dismiss='modal'>
Got It
</a>
</div>


</div>
</div>
<iframe class='l-ie-iframe-fix' tabindex='-1' title='modal'></iframe>
</div>
<ql-dialog headline='How satisfied are you with this lab?&lt;span aria-hidden=&quot;true&quot;&gt;*&lt;/span&gt;' id='lab-review-dialog'>
<form class="simple_form js-lab-review-form" id="edit_lab_review_35097566" action="/lab_reviews/35097566" accept-charset="UTF-8" data-remote="true" method="post"><input name="utf8" type="hidden" value="&#x2713;" autocomplete="off" /><input type="hidden" name="_method" value="patch" autocomplete="off" /><div aria-labelledby='lab-review-dialog' aria-required='true' aria-valuemax='5' aria-valuemin='0' aria-valuenow='5' class='rateit js-rateit' data-rateit-max='5' data-rateit-min='0' data-rateit-resetable='false' data-rateit-step='1' data-rateit-value='5' id='lab-review-rateit' role='slider' tabindex='0'></div>
<div class='l-mtm'>

<div class="control-group hidden lab_review_user_id"><div class="controls"><input class="hidden" autocomplete="off" type="hidden" value="12197799" name="lab_review[user_id]" id="lab_review_user_id" /></div></div>
<div class="control-group hidden lab_review_classroom_id"><div class="controls"><input class="hidden" autocomplete="off" type="hidden" name="lab_review[classroom_id]" id="lab_review_classroom_id" /></div></div>
<div class="control-group hidden lab_review_lab_id"><div class="controls"><input class="hidden" autocomplete="off" type="hidden" value="2187" name="lab_review[lab_id]" id="lab_review_lab_id" /></div></div>
<div class="control-group hidden lab_review_focus_id"><div class="controls"><input class="hidden" autocomplete="off" type="hidden" name="lab_review[focus_id]" id="lab_review_focus_id" /></div></div>
<div class="control-group hidden lab_review_rating"><div class="controls"><input class="hidden js-rating-input" autocomplete="off" type="hidden" value="2" name="lab_review[rating]" id="lab_review_rating" /></div></div>
<div class="control-group text optional lab_review_comment"><label class="text optional control-label" for="lab_review_comment">Additional Comments</label><div class="controls"><textarea class="text optional" name="lab_review[comment]" id="lab_review_comment">
</textarea></div></div>
</div>
</form><ql-button disabled id='submit' label='Submit' slot='action' text></ql-button>
</ql-dialog>

<ql-dialog headline='All done? If you end this lab, you will lose all your work. You may not be able to restart the lab if there is a quota limit. Are you sure you want to end this lab?' icon='error_outline' id='js-lab-are-you-sure-dialog'>
<ql-button id='js-are-you-sure-button' label='Submit' slot='action' text></ql-button>
</ql-dialog>


<script>
  $(function() {
    ql.initMaterialInputs();
    initChosen();
    initSearch();
    initTabs();
    ql.list.init();
    ql.favoriting.init();
    ql.header.myAccount.init();
    initTooltips();
    ql.autocomplete.init();
    ql.modals.init();
    ql.toggleButtons.init();
    ql.analytics.init();
    ql.chat.init();
  ql.jumpContent.init();
  ql.labControlPanel.addRecaptchaErrorHandler();
  initLabContent();
  ql.labOutline.links.init();
  initLabReviewModal();
  initLabReviewTranslations( {"star_amount_1":"1 of 5 stars","star_amount_2":"2 of 5 stars","star_amount_3":"3 of 5 stars","star_amount_4":"4 of 5 stars","star_amount_5":"5 of 5 stars"} )
  ql.labAssessment.init();
  ql.labData.init();
  initLabTranslations( {"are_you_sure":"All done? If you end this lab, you will lose all your work. You may not be able to restart the lab if there is a quota limit. Are you sure you want to end this lab?","in_progress":"*In Progress*","ending":"*Ending*","starting":"*Starting, please wait*","end_concurrent_labs":"Sorry, you can only run one lab at a time. To start this lab, please confirm that you want all of your existing labs to end.","copied":"Copied","no_resource":"Error retrieving resource.","no_support":"No Support","mac_press":"Press ⌘-C to copy","thanks_review":"Thanks for reviewing this lab.","windows_press":"Press Ctrl-C to copy","days":"days"} );
  ql.labRun.init();
  ql.navPanel.init();
  ql.navigation.init();
  
  });
</script>

</body>
</html>

